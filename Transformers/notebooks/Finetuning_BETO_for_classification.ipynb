{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning BETO for classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNA4ki34toju",
        "outputId": "c1ba1aaf-6eb4-4e0c-e76e-5f7c186a78d2"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 47.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w37KRkCtztm",
        "outputId": "c3e7bc94-3500-477c-b230-8e01f0d31a3e"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QOrGqV-t4Rh"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrpGbHVXt6c9"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/ticket_suggestion_spanish/technology_train_spanish.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "hvYyXfCeuLOu",
        "outputId": "cf6594fb-552b-43db-8b13-4abdd13a0454"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>spanish_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>ticket_yes</td>\n",
              "      <td>¿Me atraparán si descargo una película en BitT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>ticket_no</td>\n",
              "      <td>Parece que no puedo encontrar mi tarjeta dold ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>ticket_yes</td>\n",
              "      <td>¿Qué es la URL?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>ticket_yes</td>\n",
              "      <td>¿Recibo alguna notificación por quejarme de mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>ticket_no</td>\n",
              "      <td>¿Cuáles son sus horas de servicio?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>ticket_no</td>\n",
              "      <td>¿Escuchaste sobre Sam?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>ticket_yes</td>\n",
              "      <td>Mi nuevo escritorio de Windows 10 dice que Win...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>ticket_yes</td>\n",
              "      <td>El sistema operativo de mi teléfono funciona d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>ticket_yes</td>\n",
              "      <td>¿Puedo usar AirPort Express con una PC con Win...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>ticket_yes</td>\n",
              "      <td>¿Cómo me doy de baja del correo electrónico de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         labels                                       spanish_text\n",
              "167  ticket_yes  ¿Me atraparán si descargo una película en BitT...\n",
              "89    ticket_no  Parece que no puedo encontrar mi tarjeta dold ...\n",
              "271  ticket_yes                                    ¿Qué es la URL?\n",
              "195  ticket_yes  ¿Recibo alguna notificación por quejarme de mi...\n",
              "206   ticket_no                 ¿Cuáles son sus horas de servicio?\n",
              "116   ticket_no                             ¿Escuchaste sobre Sam?\n",
              "259  ticket_yes  Mi nuevo escritorio de Windows 10 dice que Win...\n",
              "78   ticket_yes  El sistema operativo de mi teléfono funciona d...\n",
              "214  ticket_yes  ¿Puedo usar AirPort Express con una PC con Win...\n",
              "219  ticket_yes  ¿Cómo me doy de baja del correo electrónico de..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwaOyfC7uNrg"
      },
      "source": [
        "def to_classes(labels):\n",
        "  if labels == 'ticket_no':\n",
        "    return 0\n",
        "  else:\n",
        "    return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRkuGZp1uP-k"
      },
      "source": [
        "df['labels']= df.labels.apply(to_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmqzMXR0uRWs"
      },
      "source": [
        "df.drop(labels='labels',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "Qet-HCk1uTAp",
        "outputId": "5ac736cb-050b-4acb-bc33-e25b067991d6"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>spanish_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>Transfiere mil rupias a mi cuenta bancaria.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>1</td>\n",
              "      <td>Mi computadora portátil está infectada con dem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>1</td>\n",
              "      <td>Este proyector está roto, ya no proyecta una i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>0</td>\n",
              "      <td>Parece que no puedo encontrar mi tarjeta dold ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>0</td>\n",
              "      <td>¿Qué es COVID-19?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0</td>\n",
              "      <td>¿Cómo actualizo mis datos personales?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>1</td>\n",
              "      <td>¿Qué hay de malo en usar una red Wi-Fi pública?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>0</td>\n",
              "      <td>¿Qué haces por tus pasatiempos?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>1</td>\n",
              "      <td>La cámara web de mi computadora portátil no fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0</td>\n",
              "      <td>Debo hacer que repitas eso.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     labels                                       spanish_text\n",
              "5         0        Transfiere mil rupias a mi cuenta bancaria.\n",
              "111       1  Mi computadora portátil está infectada con dem...\n",
              "106       1  Este proyector está roto, ya no proyecta una i...\n",
              "89        0  Parece que no puedo encontrar mi tarjeta dold ...\n",
              "220       0                                  ¿Qué es COVID-19?\n",
              "199       0              ¿Cómo actualizo mis datos personales?\n",
              "160       1    ¿Qué hay de malo en usar una red Wi-Fi pública?\n",
              "82        0                    ¿Qué haces por tus pasatiempos?\n",
              "133       1  La cámara web de mi computadora portátil no fu...\n",
              "149       0                        Debo hacer que repitas eso."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIo-nXnKuUQd",
        "outputId": "bcd0c197-7046-42fc-fe6f-4aee6aeba00d"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-uncased', do_lower_case=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adR61o1XuWJR"
      },
      "source": [
        "sentences = df.spanish_text.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOwzxE6-uY1n",
        "outputId": "ddce261d-7204-4c2d-b150-2577c0b9e835"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Buenos dias\n",
            "Tokenized:  ['buenos', 'dias']\n",
            "Token IDs:  [2931, 12873]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYXdRrdfueTE",
        "outputId": "1ec510bd-5512-492c-8ddc-46003738de4d"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrfQviT5ugeS"
      },
      "source": [
        "from torch.utils import data\n",
        "\n",
        "class TicketSuggestionDataset(data.Dataset):\n",
        "\n",
        "  def __init__(self,text,target, tokenizer, max_len):\n",
        "    self.text = text\n",
        "    self.target = target\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text)\n",
        "\n",
        "  def __getitem__(self,item):\n",
        "    text = str(self.text[item])\n",
        "    encoder = tokenizer.encode_plus(\n",
        "                          text,\n",
        "                          max_length = self.max_len,\n",
        "                          add_special_tokens = True,\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,\n",
        "                          return_token_type_ids = False,\n",
        "                          return_tensors = 'pt'\n",
        "                      )\n",
        "    return {\n",
        "        'text':text,\n",
        "        'input_ids': encoder['input_ids'].flatten(),\n",
        "        'attention_mask': encoder['attention_mask'].flatten(),\n",
        "        'targets' : torch.tensor(self.target[item],dtype = torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVGON1MDui3f"
      },
      "source": [
        "ds = TicketSuggestionDataset(\n",
        "      text = sentences,\n",
        "      target = labels,\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = 40\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_sc544euk9B",
        "outputId": "89f89de4-a908-4727-a4b7-b616839929e8"
      },
      "source": [
        "ds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': tensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'input_ids': tensor([    4,  2931, 12873,     5,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]),\n",
              " 'targets': tensor(0),\n",
              " 'text': 'Buenos dias'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOeApZZnumRY"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q96j30d5uoKs"
      },
      "source": [
        "def create_dataloader(df,tokenizer,max_len,batch_size):\n",
        "\n",
        "  ds = TicketSuggestionDataset(\n",
        "      text = df.spanish_text.to_numpy(),\n",
        "      target = df.label.to_numpy(),\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = max_len\n",
        "      )\n",
        "  \n",
        "  return data.DataLoader(\n",
        "      ds,\n",
        "      batch_size = batch_size,\n",
        "      sampler = RandomSampler(ds)\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmHs26OXup0S"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2ybcWXdurNE"
      },
      "source": [
        "df_train, df_val = train_test_split(\n",
        "  df,\n",
        "  test_size=0.2,\n",
        "  random_state=42,\n",
        "  stratify = df['label']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arqI9HtlusnT"
      },
      "source": [
        "train_dataloader = create_dataloader(df_train,tokenizer,40,16)\n",
        "val_dataloader = create_dataloader(df_val, tokenizer, 40, 8)\n",
        "#batch_size = 40 for billing\n",
        "#batch_size = 32 for technology"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QoDy27juunk",
        "outputId": "62d8b8e5-7cb4-48ee-de81-fd4424df2da8"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"dccuchile/bert-base-spanish-wwm-uncased\",\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['classifier.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgpMx7WDuxS5"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 3e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kxzLfnTu38g"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRwP1ev5u7Ht"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVYNTaHiu8jc"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWnnyqKiu-WB"
      },
      "source": [
        "def train(model,dataloader,device,optimizer,scheduler):\n",
        "  \n",
        "  t0 = time.time()\n",
        "\n",
        "  # Put the model into training mode. Don't be mislead--the call to \n",
        "  # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "  # `dropout` and `batchnorm` layers behave differently during training\n",
        "  # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "  model.train()\n",
        "  # Reset the total loss for this epoch.\n",
        "  total_train_loss = 0\n",
        "\n",
        "  # For each batch of training data...\n",
        "  for step, batch in enumerate(dataloader):\n",
        "\n",
        "      # Progress update every 40 batches.\n",
        "      if step % 5 == 0 and not step == 0:\n",
        "          # Calculate elapsed time in minutes.\n",
        "          elapsed = format_time(time.time() - t0)\n",
        "          \n",
        "          # Report progress.\n",
        "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(dataloader), elapsed))\n",
        "\n",
        "      # Unpack this training batch from our dataloader. \n",
        "      #\n",
        "      # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "      # `to` method.\n",
        "      #\n",
        "      # `batch` contains dictionary with keys:\n",
        "      #   text \n",
        "      #   input_ids\n",
        "      #   attention_masks\n",
        "      #   targets\n",
        "      b_input_ids = batch['input_ids'].to(device)\n",
        "      b_input_mask = batch['attention_mask'].to(device)\n",
        "      b_labels = batch['targets'].to(device)\n",
        "\n",
        "      # Always clear any previously calculated gradients before performing a\n",
        "      # backward pass. PyTorch doesn't do this automatically because \n",
        "      # accumulating the gradients is \"convenient while training RNNs\". \n",
        "      # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "      model.zero_grad()        \n",
        "\n",
        "      # Perform a forward pass (evaluate the model on this training batch).\n",
        "      # The documentation for this `model` function is here: \n",
        "      # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "      # It returns different numbers of parameters depending on what arguments\n",
        "      # arge given and what flags are set. For our useage here, it returns\n",
        "      # the loss (because we provided labels) and the \"logits\"--the model\n",
        "      # outputs prior to activation.\n",
        "      loss_logits = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "\n",
        "      # Accumulate the training loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value \n",
        "      # from the tensor.\n",
        "      total_train_loss += loss_logits[0].item()\n",
        "\n",
        "      # Perform a backward pass to calculate the gradients.\n",
        "      loss_logits[0].backward()\n",
        "\n",
        "      # Clip the norm of the gradients to 1.0.\n",
        "      # This is to help prevent the \"exploding gradients\" problem.\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      # Update parameters and take a step using the computed gradient.\n",
        "      # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "      # modified based on their gradients, the learning rate, etc.\n",
        "      optimizer.step()\n",
        "\n",
        "      # Update the learning rate.\n",
        "      scheduler.step()\n",
        "\n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "  \n",
        "  # Measure how long this epoch took.\n",
        "  training_time = format_time(time.time() - t0)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "      \n",
        "  return avg_train_loss,training_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_lWkcMNvAMG"
      },
      "source": [
        "def eval_model(model,dataloader,device):\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  # Put the model in evaluation mode--the dropout layers behave differently\n",
        "  # during evaluation.\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  total_eval_accuracy = 0\n",
        "  total_eval_loss = 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in dataloader:\n",
        "      \n",
        "      # Unpack this training batch from our dataloader. \n",
        "      #\n",
        "      # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "      # the `to` method.\n",
        "      #\n",
        "      # `batch` contains three pytorch tensors:\n",
        "      #   [0]: input ids \n",
        "      #   [1]: attention masks\n",
        "      #   [2]: labels \n",
        "      b_input_ids = batch['input_ids'].to(device)\n",
        "      b_input_mask = batch['attention_mask'].to(device)\n",
        "      b_labels = batch['targets'].to(device)\n",
        "      \n",
        "      # Tell pytorch not to bother with constructing the compute graph during\n",
        "      # the forward pass, since this is only needed for backprop (training).\n",
        "      with torch.no_grad():        \n",
        "\n",
        "          # Forward pass, calculate logit predictions.\n",
        "          # token_type_ids is the same as the \"segment ids\", which \n",
        "          # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "          # The documentation for this `model` function is here: \n",
        "          # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "          # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "          # values prior to applying an activation function like the softmax.\n",
        "          loss_logits_val = model(b_input_ids, \n",
        "                                  token_type_ids=None, \n",
        "                                  attention_mask=b_input_mask,\n",
        "                                  labels=b_labels)\n",
        "          \n",
        "      # Accumulate the validation loss.\n",
        "      total_eval_loss += loss_logits_val[0].item()\n",
        "\n",
        "      # Move logits and labels to CPU\n",
        "      logits = loss_logits_val[1].detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      # Calculate the accuracy for this batch of test sentences, and\n",
        "      # accumulate it over all batches.\n",
        "      total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "      \n",
        "\n",
        "  # Report the final accuracy for this validation run.\n",
        "  avg_val_accuracy = total_eval_accuracy / len(dataloader)\n",
        "  print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "  # Calculate the average loss over all of the batches.\n",
        "  avg_val_loss = total_eval_loss / len(dataloader)\n",
        "  \n",
        "  # Measure how long the validation run took.\n",
        "  validation_time = format_time(time.time() - t0)\n",
        "  \n",
        "  print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "  print(\"  Validation took: {:}\".format(validation_time))\n",
        "  return avg_val_accuracy,avg_val_loss,validation_time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPdgZ9JavBoG",
        "outputId": "becbb1fd-afbd-4e52-cfa4-c8534d6388c1"
      },
      "source": [
        "training_stats = []\n",
        "for epochs in range(4):\n",
        "  print(\"\")\n",
        "  print('======== Epoch {:} / {:} ========'.format(epochs + 1, 4))\n",
        "  print('Training...')\n",
        "  train_loss, training_time = train(\n",
        "      model,\n",
        "      train_dataloader,\n",
        "      device,\n",
        "      optimizer,\n",
        "      scheduler\n",
        "  )\n",
        "  val_acc, val_loss, validation_time = eval_model(\n",
        "      model,\n",
        "      val_dataloader,\n",
        "      device\n",
        "  )\n",
        "\n",
        "  # Record all statistics from this epoch.\n",
        "  training_stats.append(\n",
        "        {\n",
        "            'epoch': epochs + 1,\n",
        "            'Training Loss': train_loss,\n",
        "            'Valid. Loss': val_loss,\n",
        "            'Valid. Accur.': val_acc,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch     5  of     15.    Elapsed: 0:00:01.\n",
            "  Batch    10  of     15.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.16\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch     5  of     15.    Elapsed: 0:00:01.\n",
            "  Batch    10  of     15.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.09\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.06\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch     5  of     15.    Elapsed: 0:00:01.\n",
            "  Batch    10  of     15.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.09\n",
            "  Validation took: 0:00:00\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch     5  of     15.    Elapsed: 0:00:01.\n",
            "  Batch    10  of     15.    Elapsed: 0:00:03.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:00:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.10\n",
            "  Validation took: 0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9cb5CIgMa3y"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx3Z_SoYvDor",
        "outputId": "81a58dd3-5d39-40fd-a5f7-e538935d2fc0"
      },
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/ticket_suggestion_spanish/testcases_ticketsuggestion _tech_spanish_reduced.csv\")\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df_test.shape[0]))\n",
        "df_test['label']= df_test.actual_labels.apply(to_classes)\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df_test.spanish_text.values\n",
        "labels = df_test.label.values\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 59\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip5MGsPYMuAm"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bWQq46YvK-q"
      },
      "source": [
        "test_dataloader = create_dataloader(df_test,tokenizer,40,8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh_JXgRDvUYr",
        "outputId": "ada1f82a-04ac-46be-e3b4-422364f9beef"
      },
      "source": [
        "test_acc, test_loss, test_time = eval_model(\n",
        "      model,\n",
        "      test_dataloader,\n",
        "      device\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.04\n",
            "  Validation took: 0:00:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPmJQDDovVk7"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        token_type_ids=None,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      # print(torch.max(outputs[0], dim=1))\n",
        "      _, preds = torch.max(outputs[0], dim=1)\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      real_values.extend(targets)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, real_values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RApCkTLAvept",
        "outputId": "c0d55e3d-7047-456e-98e9-b81922abec11"
      },
      "source": [
        "text,prediction,actual = get_predictions(\n",
        "  model,\n",
        "  test_dataloader\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Yemkwhcrai"
      },
      "source": [
        "def create_dataframe(text, pred, actual):\n",
        "    res = {\n",
        "        'text': text,\n",
        "        'Predictions': pred,\n",
        "        'Actual': actual\n",
        "    }\n",
        "    result = pd.DataFrame(res)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_classes(label):\n",
        "    if label == 0:\n",
        "        return \"ticket_no\"\n",
        "    else:\n",
        "        return \"ticket_yes\"\n",
        "\n",
        "def convert_label_class(df):\n",
        "    df['Predictions'] = df.Predictions.apply(get_classes)\n",
        "    df['Actual'] = df.Actual.apply(get_classes)\n",
        "\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQRjWhddvhDg"
      },
      "source": [
        "result = pd.DataFrame({'text':text,'Prediction':prediction,'Actual':actual})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "RPwgn6ZXwTvm",
        "outputId": "6c86cdb5-59be-4959-d765-e27c9ab8964f"
      },
      "source": [
        "final_result[final_result['Predictions']!=final_result['Actual']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>Predictions</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>¿Cómo sé si me estoy quedando sin RAM?</td>\n",
              "      <td>ticket_no</td>\n",
              "      <td>ticket_yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      text Predictions      Actual\n",
              "36  ¿Cómo sé si me estoy quedando sin RAM?   ticket_no  ticket_yes"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmqCfUSTwbWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e1cb15-87a7-4bf9-9785-e7416128eaf8"
      },
      "source": [
        "result = create_dataframe(text,prediction,actual)\n",
        "\n",
        "final_result = convert_label_class(result)\n",
        "\n",
        "print(final_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 text Predictions      Actual\n",
            "0                  ¿Cómo configuro VPN en mi sistema?  ticket_yes  ticket_yes\n",
            "1                                 Hola cómo estás hoy   ticket_no   ticket_no\n",
            "2              ¿Cuál es la cantidad mínima de pedido?   ticket_no   ticket_no\n",
            "3   Mi computadora funciona lento, creo que tengo ...  ticket_yes  ticket_yes\n",
            "4   ¿Cuánto tiempo puede durar un cable HDMI y seg...  ticket_yes  ticket_yes\n",
            "5                    ¿Cómo puedo arreglar mi teclado?  ticket_yes  ticket_yes\n",
            "6                      mi computadora no se enciende.  ticket_yes  ticket_yes\n",
            "7                   ¿Qué es un televisor inteligente?  ticket_yes  ticket_yes\n",
            "8                                 como hago una pizza   ticket_no   ticket_no\n",
            "9   La pantalla de mi computadora portátil no se e...  ticket_yes  ticket_yes\n",
            "10                 mi enrutador y módem no funcionan.  ticket_yes  ticket_yes\n",
            "11                            la tv no recibe entrada  ticket_yes  ticket_yes\n",
            "12                      ¿puedo comer una hamburguesa?   ticket_no   ticket_no\n",
            "13                  mi correo electrónico no funciona  ticket_yes  ticket_yes\n",
            "14  ¿Cuál es la cantidad mínima de pedido para el ...   ticket_no   ticket_no\n",
            "15                     mi teléfono estaba en el agua.  ticket_yes  ticket_yes\n",
            "16                       Probé negativo para COVID-19   ticket_no   ticket_no\n",
            "17       ¿Cuánto tiempo puede tener el cable HDMI 4K?  ticket_yes  ticket_yes\n",
            "18                          Tengo una llanta pinchada   ticket_no   ticket_no\n",
            "19                         Parece que va a llover hoy   ticket_no   ticket_no\n",
            "20                                donde estais chicos   ticket_no   ticket_no\n",
            "21  No pude configurar las configuraciones en mi c...  ticket_yes  ticket_yes\n",
            "22     ¿Puedes sugerirme un buen libro de no ficción?   ticket_no   ticket_no\n",
            "23            mi batería se está cargando lentamente.  ticket_yes  ticket_yes\n",
            "24                          No me siento tan bien hoy   ticket_no   ticket_no\n",
            "25  Estoy usando Windows 7 y he actualizado mis co...  ticket_yes  ticket_yes\n",
            "26                           ¿HDMI necesita blindaje?  ticket_yes  ticket_yes\n",
            "27  ¿Puedo descargar la última actualización de fi...  ticket_yes  ticket_yes\n",
            "28                          ¿porque el cielo es azul?   ticket_no   ticket_no\n",
            "29   hay una impresora que no funciona correctamente.  ticket_yes  ticket_yes\n",
            "30       ¿Cuánto tiempo se tarda en llegar la comida?   ticket_no   ticket_no\n",
            "31               ¿Por qué mi Internet funciona lento?  ticket_yes  ticket_yes\n",
            "32            no recibe información de la televisión.  ticket_yes  ticket_yes\n",
            "33                el gato está durmiendo en la silla.   ticket_no   ticket_no\n",
            "34         ¿Hay alguna diferencia en los cables HDMI?  ticket_yes  ticket_yes\n",
            "35                        Estoy pensando en ir al kfc   ticket_no   ticket_no\n",
            "36             ¿Cómo sé si me estoy quedando sin RAM?   ticket_no  ticket_yes\n",
            "37                 ¿Cuáles son sus opciones de envío?   ticket_no   ticket_no\n",
            "38            No puedo abrir ninguna página en Chrome  ticket_yes  ticket_yes\n",
            "39  Estoy usando Windows 98, ¿cómo puedo actualiza...  ticket_yes  ticket_yes\n",
            "40  ¿Los precios y las promociones son los mismos ...   ticket_no   ticket_no\n",
            "41                       no puedo acceder a internet.  ticket_yes  ticket_yes\n",
            "42     ¿Cómo se calcula el impuesto sobre las ventas?   ticket_no   ticket_no\n",
            "43  Bloqueé una categoría usando ViaSecure, pero n...  ticket_yes  ticket_yes\n",
            "44  ¿Cuándo se realiza el cargo en mi tarjeta de c...   ticket_no   ticket_no\n",
            "45  La oficina permanecerá cerrada el martes debid...   ticket_no   ticket_no\n",
            "46     el televisor no recibe entrada del cable hdmi.  ticket_yes  ticket_yes\n",
            "47  No sé si necesito un controlador para el micró...  ticket_yes  ticket_yes\n",
            "48                             dejé caer mi teléfono.  ticket_yes  ticket_yes\n",
            "49                          ¿Tienes tu propia cocina?   ticket_no   ticket_no\n",
            "50                 ¿Cuál es su política de reembolso?   ticket_no   ticket_no\n",
            "51           oye, ¿por qué no funciona mi cámara web?  ticket_yes  ticket_yes\n",
            "52     ¿Bloqueo específico de dispositivo disponible?  ticket_yes  ticket_yes\n",
            "53         mi enrutador no tiene conexión a Internet.  ticket_yes  ticket_yes\n",
            "54  Me encantan todas las decoraciones artísticas ...   ticket_no   ticket_no\n",
            "55                          ¿quien descubrio America?   ticket_no   ticket_no\n",
            "56  ¿Cómo obtengo una copia de mi factura / orden ...   ticket_no   ticket_no\n",
            "57                          ¿Qué es un enrutador ONU?  ticket_yes  ticket_yes\n",
            "58                              ¿Dónde entregas todo?   ticket_no   ticket_no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxHCoaUWx6QR",
        "outputId": "82fffa19-5776-4054-c954-b83e0ed91146"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/ticket_suggestion_spanish/model_finetune_BETO_uncased/technology'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to /content/drive/MyDrive/ticket_suggestion_spanish/model_finetune_BETO_uncased/technology\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/ticket_suggestion_spanish/model_finetune_BETO_uncased/technology/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/ticket_suggestion_spanish/model_finetune_BETO_uncased/technology/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/ticket_suggestion_spanish/model_finetune_BETO_uncased/technology/vocab.txt',\n",
              " '/content/drive/MyDrive/ticket_suggestion_spanish/model_finetune_BETO_uncased/technology/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndwuEyHuzF_i"
      },
      "source": [
        "### ON RAW TEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX_cEOhrzXAG"
      },
      "source": [
        "class_names= ['ticket_no','ticket_yes']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgmrO69DyAAL"
      },
      "source": [
        "review_text = 'Quiero mi efectivo en paypal'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QetGizxAzNu5",
        "outputId": "270b7a07-c83b-4522-ca94-28b4ee8e2740"
      },
      "source": [
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2204: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X4Kq13zzSZM",
        "outputId": "c36ee3bb-2d6b-4f94-ab8d-d5e93df74a39"
      },
      "source": [
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "output = model(input_ids,attention_mask)\n",
        "_, prediction = torch.max(output[0], dim=1)\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review text: Quiero mi efectivo en paypal\n",
            "Sentiment  : ticket_yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wXn1dSyzwyu"
      },
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiAP3bjG__Sh"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"/content/drive/MyDrive/ticket_suggestion_spanish/model_finetune_BETO_cased/technology\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMVDEbtpAHYY"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/ticket_suggestion_spanish/model_finetune_BETO_cased/technology\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApHjKeLrALIH",
        "outputId": "73b1c56d-f6a4-4cd8-8748-cb07214ff811"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9owwKm9NHU-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}